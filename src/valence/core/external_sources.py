"""External Source Verification for Valence L4 Elevation.

This module implements external source verification requirements per THREAT-MODEL.md ยง1.4.2.
For L4 elevation (Communal Knowledge), beliefs must cite at least one machine-verifiable
external source that:
1. Can be resolved (URL/DOI liveness check)
2. Actually supports the claimed belief (content matching via NLP similarity)
3. Comes from a trusted or known source category

This prevents the independence oracle from being gamed by coordinated false beliefs
that cite fabricated or non-existent sources.

Spec reference: spec/components/consensus-mechanism/EXTERNAL-SOURCES.md
Threat reference: spec/security/THREAT-MODEL.md ยง1.4.2
"""

from __future__ import annotations

import hashlib
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any
from urllib.parse import urlparse
from uuid import UUID, uuid4

logger = logging.getLogger(__name__)


# =============================================================================
# CONSTANTS
# =============================================================================

class ExternalSourceConstants:
    """Configuration constants for external source verification."""
    
    # Liveness check configuration
    LIVENESS_CHECK_TIMEOUT_SECONDS = 30
    LIVENESS_CACHE_TTL_HOURS = 24
    MAX_CONTENT_FETCH_BYTES = 10 * 1024 * 1024  # 10MB max
    
    # Content matching thresholds
    MIN_CONTENT_SIMILARITY = 0.65  # Minimum semantic similarity to claim
    HIGH_CONTENT_SIMILARITY = 0.85  # Strong support threshold
    
    # Source reliability defaults
    DEFAULT_SOURCE_RELIABILITY = 0.5
    ACADEMIC_SOURCE_RELIABILITY = 0.8
    GOVERNMENT_SOURCE_RELIABILITY = 0.75
    NEWS_SOURCE_RELIABILITY = 0.6
    UNKNOWN_SOURCE_RELIABILITY = 0.3
    
    # L4 elevation requirements
    MIN_EXTERNAL_SOURCES_FOR_L4 = 1
    MIN_VERIFIED_SOURCE_RELIABILITY = 0.5
    MIN_CONTENT_MATCH_SCORE = 0.65
    
    # Rate limiting
    MAX_VERIFICATIONS_PER_SOURCE_PER_HOUR = 10
    MAX_SOURCES_PER_BELIEF = 20
    
    # Source freshness
    STALE_SOURCE_THRESHOLD_DAYS = 365 * 2  # 2 years
    RECENT_SOURCE_BONUS = 0.1  # Bonus for sources < 30 days old


# =============================================================================
# ENUMS
# =============================================================================

class SourceCategory(str, Enum):
    """Categories of external sources with different trust levels."""
    ACADEMIC_JOURNAL = "academic_journal"         # Peer-reviewed journals
    ACADEMIC_PREPRINT = "academic_preprint"       # arXiv, bioRxiv, etc.
    GOVERNMENT = "government"                      # .gov, official stats
    NEWS_MAJOR = "news_major"                      # Reuters, AP, major outlets
    NEWS_REGIONAL = "news_regional"                # Regional news
    ENCYCLOPEDIA = "encyclopedia"                  # Wikipedia, Britannica
    TECHNICAL_DOCS = "technical_docs"              # RFCs, specs, docs
    SOCIAL_VERIFIED = "social_verified"            # Verified accounts
    CORPORATE = "corporate"                        # Company press releases
    PERSONAL_BLOG = "personal_blog"                # Blogs, personal sites
    UNKNOWN = "unknown"                            # Unclassified
    
    @property
    def base_reliability(self) -> float:
        """Get base reliability score for this category."""
        return {
            SourceCategory.ACADEMIC_JOURNAL: 0.90,
            SourceCategory.ACADEMIC_PREPRINT: 0.75,
            SourceCategory.GOVERNMENT: 0.80,
            SourceCategory.NEWS_MAJOR: 0.70,
            SourceCategory.NEWS_REGIONAL: 0.55,
            SourceCategory.ENCYCLOPEDIA: 0.65,
            SourceCategory.TECHNICAL_DOCS: 0.85,
            SourceCategory.SOCIAL_VERIFIED: 0.50,
            SourceCategory.CORPORATE: 0.55,
            SourceCategory.PERSONAL_BLOG: 0.35,
            SourceCategory.UNKNOWN: 0.30,
        }[self]


class SourceVerificationStatus(str, Enum):
    """Status of source verification."""
    PENDING = "pending"              # Not yet verified
    VERIFIED = "verified"            # Successfully verified
    FAILED_LIVENESS = "failed_liveness"  # Source URL/DOI doesn't resolve
    FAILED_CONTENT = "failed_content"    # Content doesn't match claim
    FAILED_RELIABILITY = "failed_reliability"  # Source too unreliable
    EXPIRED = "expired"              # Verification expired, needs refresh
    BLOCKED = "blocked"              # Source is blocklisted


class DOIStatus(str, Enum):
    """Status of DOI resolution."""
    VALID = "valid"                  # DOI resolves to content
    INVALID = "invalid"              # DOI doesn't exist
    RETRACTED = "retracted"          # Paper has been retracted
    UNKNOWN = "unknown"              # Could not determine


class SourceLivenessStatus(str, Enum):
    """Result of liveness check."""
    LIVE = "live"                    # Source accessible
    DEAD = "dead"                    # Source not accessible (404, etc)
    TIMEOUT = "timeout"              # Request timed out
    BLOCKED = "blocked"              # Access blocked (paywall, geo, etc)
    REDIRECT = "redirect"            # Redirected to different content
    ERROR = "error"                  # Other error


# =============================================================================
# TRUSTED SOURCE REGISTRY
# =============================================================================

@dataclass
class TrustedDomain:
    """A domain registered as a trusted source."""
    
    domain: str
    category: SourceCategory
    reliability_override: float | None = None  # Override category default
    
    # Verification requirements
    require_https: bool = True
    allowed_paths: list[str] | None = None  # Regex patterns, None = all
    blocked_paths: list[str] | None = None  # Regex patterns to block
    
    # Metadata
    added_at: datetime = field(default_factory=datetime.now)
    added_by: str | None = None  # DID of admin who added
    notes: str | None = None
    
    @property
    def reliability(self) -> float:
        """Get effective reliability score."""
        return self.reliability_override or self.category.base_reliability
    
    def matches_url(self, url: str) -> bool:
        """Check if URL matches this trusted domain."""
        try:
            parsed = urlparse(url)
            host = parsed.netloc.lower()
            
            # Check domain - must be exact match or subdomain (with dot separator)
            if host == self.domain:
                pass  # Exact match
            elif host.endswith("." + self.domain):
                pass  # Subdomain match
            elif self.domain.startswith(".") and host.endswith(self.domain):
                pass  # Suffix match (e.g., .gov)
            else:
                return False
            
            # Check HTTPS requirement
            if self.require_https and parsed.scheme != "https":
                return False
            
            # Check blocked paths
            if self.blocked_paths:
                for pattern in self.blocked_paths:
                    if re.match(pattern, parsed.path):
                        return False
            
            # Check allowed paths
            if self.allowed_paths:
                return any(re.match(pattern, parsed.path) for pattern in self.allowed_paths)
            
            return True
        except (ValueError, re.error):
            # ValueError: invalid URL, re.error: invalid regex pattern
            return False
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "domain": self.domain,
            "category": self.category.value,
            "reliability": self.reliability,
            "reliability_override": self.reliability_override,
            "require_https": self.require_https,
            "allowed_paths": self.allowed_paths,
            "blocked_paths": self.blocked_paths,
            "added_at": self.added_at.isoformat(),
            "added_by": self.added_by,
            "notes": self.notes,
        }


@dataclass
class DOIPrefix:
    """A registered DOI prefix (publisher identifier)."""
    
    prefix: str  # e.g., "10.1038" for Nature
    publisher: str
    category: SourceCategory = SourceCategory.ACADEMIC_JOURNAL
    reliability_override: float | None = None
    known_retraction_policy: bool = True
    
    @property
    def reliability(self) -> float:
        """Get effective reliability score."""
        return self.reliability_override or self.category.base_reliability
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "prefix": self.prefix,
            "publisher": self.publisher,
            "category": self.category.value,
            "reliability": self.reliability,
            "known_retraction_policy": self.known_retraction_policy,
        }


class TrustedSourceRegistry:
    """Registry of trusted external sources.
    
    This registry maintains lists of:
    - Trusted domains (with category and reliability)
    - Known DOI prefixes (publishers)
    - Blocklisted domains (malicious or unreliable)
    
    In production, this would be backed by a database.
    """
    
    def __init__(self):
        self._domains: dict[str, TrustedDomain] = {}
        self._doi_prefixes: dict[str, DOIPrefix] = {}
        self._blocklist: set[str] = set()
        self._load_defaults()
    
    def _load_defaults(self):
        """Load default trusted sources."""
        # Academic/Research
        self.register_domain(TrustedDomain(
            domain="doi.org", category=SourceCategory.ACADEMIC_JOURNAL
        ))
        self.register_domain(TrustedDomain(
            domain="arxiv.org", category=SourceCategory.ACADEMIC_PREPRINT
        ))
        self.register_domain(TrustedDomain(
            domain="pubmed.ncbi.nlm.nih.gov", category=SourceCategory.ACADEMIC_JOURNAL
        ))
        self.register_domain(TrustedDomain(
            domain="scholar.google.com", category=SourceCategory.ACADEMIC_JOURNAL
        ))
        self.register_domain(TrustedDomain(
            domain="ncbi.nlm.nih.gov", category=SourceCategory.ACADEMIC_JOURNAL
        ))
        self.register_domain(TrustedDomain(
            domain="semanticscholar.org", category=SourceCategory.ACADEMIC_JOURNAL
        ))
        
        # Government
        self.register_domain(TrustedDomain(
            domain=".gov", category=SourceCategory.GOVERNMENT
        ))
        self.register_domain(TrustedDomain(
            domain=".gov.uk", category=SourceCategory.GOVERNMENT
        ))
        self.register_domain(TrustedDomain(
            domain="europa.eu", category=SourceCategory.GOVERNMENT
        ))
        
        # Technical documentation
        self.register_domain(TrustedDomain(
            domain="rfc-editor.org", category=SourceCategory.TECHNICAL_DOCS
        ))
        self.register_domain(TrustedDomain(
            domain="w3.org", category=SourceCategory.TECHNICAL_DOCS
        ))
        self.register_domain(TrustedDomain(
            domain="ietf.org", category=SourceCategory.TECHNICAL_DOCS
        ))
        
        # Encyclopedia
        self.register_domain(TrustedDomain(
            domain="wikipedia.org", category=SourceCategory.ENCYCLOPEDIA
        ))
        self.register_domain(TrustedDomain(
            domain="britannica.com", category=SourceCategory.ENCYCLOPEDIA
        ))
        
        # News (major)
        for domain in ["reuters.com", "apnews.com", "bbc.com", "bbc.co.uk"]:
            self.register_domain(TrustedDomain(
                domain=domain, category=SourceCategory.NEWS_MAJOR
            ))
        
        # DOI prefixes (major academic publishers)
        self.register_doi_prefix(DOIPrefix(
            prefix="10.1038", publisher="Nature Publishing Group"
        ))
        self.register_doi_prefix(DOIPrefix(
            prefix="10.1126", publisher="Science/AAAS"
        ))
        self.register_doi_prefix(DOIPrefix(
            prefix="10.1016", publisher="Elsevier"
        ))
        self.register_doi_prefix(DOIPrefix(
            prefix="10.1371", publisher="PLOS"
        ))
        self.register_doi_prefix(DOIPrefix(
            prefix="10.1145", publisher="ACM"
        ))
        self.register_doi_prefix(DOIPrefix(
            prefix="10.1109", publisher="IEEE"
        ))
        self.register_doi_prefix(DOIPrefix(
            prefix="10.48550", publisher="arXiv",
            category=SourceCategory.ACADEMIC_PREPRINT
        ))
    
    def register_domain(self, domain: TrustedDomain) -> None:
        """Register a trusted domain."""
        self._domains[domain.domain] = domain
        logger.info(f"Registered trusted domain: {domain.domain} ({domain.category.value})")
    
    def unregister_domain(self, domain: str) -> bool:
        """Unregister a domain. Returns True if it existed."""
        if domain in self._domains:
            del self._domains[domain]
            return True
        return False
    
    def register_doi_prefix(self, prefix: DOIPrefix) -> None:
        """Register a known DOI prefix."""
        self._doi_prefixes[prefix.prefix] = prefix
        logger.info(f"Registered DOI prefix: {prefix.prefix} ({prefix.publisher})")
    
    def add_to_blocklist(self, domain: str, reason: str | None = None) -> None:
        """Add domain to blocklist."""
        self._blocklist.add(domain)
        logger.warning(f"Blocklisted domain: {domain} (reason: {reason})")
    
    def remove_from_blocklist(self, domain: str) -> bool:
        """Remove domain from blocklist."""
        if domain in self._blocklist:
            self._blocklist.remove(domain)
            return True
        return False
    
    def is_blocklisted(self, url: str) -> bool:
        """Check if URL's domain is blocklisted."""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            return any(domain.endswith(blocked) for blocked in self._blocklist)
        except ValueError:
            # Invalid URL format
            return False
    
    def get_domain_info(self, url: str) -> TrustedDomain | None:
        """Get trusted domain info for a URL, if registered."""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # Check exact match first
            if domain in self._domains:
                if self._domains[domain].matches_url(url):
                    return self._domains[domain]
            
            # Check suffix matches (e.g., .gov)
            for registered, info in self._domains.items():
                if registered.startswith(".") and domain.endswith(registered):
                    if info.matches_url(url):
                        return info
                elif domain.endswith("." + registered):
                    if info.matches_url(url):
                        return info
            
            return None
        except (ValueError, re.error):
            # ValueError: invalid URL, re.error: invalid regex in matches_url()
            return None
    
    def get_doi_prefix_info(self, doi: str) -> DOIPrefix | None:
        """Get DOI prefix info if the prefix is registered."""
        # DOI format: 10.xxxx/... where 10.xxxx is the prefix
        match = re.match(r'^(10\.\d+)/', doi)
        if match:
            prefix = match.group(1)
            return self._doi_prefixes.get(prefix)
        return None
    
    def classify_source(self, url: str | None = None, doi: str | None = None) -> SourceCategory:
        """Classify an external source's category."""
        if doi:
            prefix_info = self.get_doi_prefix_info(doi)
            if prefix_info:
                return prefix_info.category
            return SourceCategory.ACADEMIC_JOURNAL  # Default for DOIs
        
        if url:
            domain_info = self.get_domain_info(url)
            if domain_info:
                return domain_info.category
            
            # Heuristic classification
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            if ".gov" in domain:
                return SourceCategory.GOVERNMENT
            if "arxiv" in domain or "preprint" in domain:
                return SourceCategory.ACADEMIC_PREPRINT
            if any(x in domain for x in [".edu", "university", "research"]):
                return SourceCategory.ACADEMIC_JOURNAL
            if any(x in domain for x in ["news", "times", "post", "herald"]):
                return SourceCategory.NEWS_REGIONAL
        
        return SourceCategory.UNKNOWN
    
    def get_source_reliability(
        self, 
        url: str | None = None, 
        doi: str | None = None
    ) -> float:
        """Get reliability score for a source."""
        if doi:
            prefix_info = self.get_doi_prefix_info(doi)
            if prefix_info:
                return prefix_info.reliability
            return SourceCategory.ACADEMIC_JOURNAL.base_reliability
        
        if url:
            if self.is_blocklisted(url):
                return 0.0
            
            domain_info = self.get_domain_info(url)
            if domain_info:
                return domain_info.reliability
            
            category = self.classify_source(url=url)
            return category.base_reliability
        
        return ExternalSourceConstants.UNKNOWN_SOURCE_RELIABILITY
    
    def to_dict(self) -> dict[str, Any]:
        """Export registry as dictionary."""
        return {
            "domains": {k: v.to_dict() for k, v in self._domains.items()},
            "doi_prefixes": {k: v.to_dict() for k, v in self._doi_prefixes.items()},
            "blocklist": list(self._blocklist),
        }


# Global registry instance
_registry: TrustedSourceRegistry | None = None

def get_registry() -> TrustedSourceRegistry:
    """Get or create the global trusted source registry."""
    global _registry
    if _registry is None:
        _registry = TrustedSourceRegistry()
    return _registry


# =============================================================================
# EXTERNAL SOURCE VERIFICATION
# =============================================================================

@dataclass
class LivenessCheckResult:
    """Result of a source liveness check."""
    
    status: SourceLivenessStatus
    http_status: int | None = None
    final_url: str | None = None  # After redirects
    content_type: str | None = None
    content_length: int | None = None
    checked_at: datetime = field(default_factory=datetime.now)
    error_message: str | None = None
    response_time_ms: int | None = None
    
    @property
    def is_live(self) -> bool:
        """Check if source is accessible."""
        return self.status == SourceLivenessStatus.LIVE
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "status": self.status.value,
            "is_live": self.is_live,
            "http_status": self.http_status,
            "final_url": self.final_url,
            "content_type": self.content_type,
            "content_length": self.content_length,
            "checked_at": self.checked_at.isoformat(),
            "error_message": self.error_message,
            "response_time_ms": self.response_time_ms,
        }


@dataclass
class ContentMatchResult:
    """Result of content similarity analysis."""
    
    similarity_score: float  # 0.0-1.0
    matched_passages: list[str] = field(default_factory=list)
    method: str = "semantic"  # 'semantic', 'keyword', 'exact'
    analyzed_at: datetime = field(default_factory=datetime.now)
    
    # Details
    claim_embedding_hash: str | None = None
    content_embedding_hash: str | None = None
    content_length_chars: int | None = None
    
    @property
    def meets_threshold(self) -> bool:
        """Check if similarity meets minimum threshold for L4."""
        return self.similarity_score >= ExternalSourceConstants.MIN_CONTENT_SIMILARITY
    
    @property
    def strongly_supports(self) -> bool:
        """Check if content strongly supports the claim."""
        return self.similarity_score >= ExternalSourceConstants.HIGH_CONTENT_SIMILARITY
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "similarity_score": self.similarity_score,
            "meets_threshold": self.meets_threshold,
            "strongly_supports": self.strongly_supports,
            "matched_passages": self.matched_passages,
            "method": self.method,
            "analyzed_at": self.analyzed_at.isoformat(),
            "content_length_chars": self.content_length_chars,
        }


@dataclass
class DOIVerificationResult:
    """Result of DOI verification."""
    
    doi: str
    status: DOIStatus
    
    # Resolved metadata
    title: str | None = None
    authors: list[str] = field(default_factory=list)
    publication_date: datetime | None = None
    journal: str | None = None
    abstract: str | None = None
    
    # Verification
    retracted: bool = False
    retraction_date: datetime | None = None
    retraction_reason: str | None = None
    
    # Reliability
    publisher_reliability: float | None = None
    
    verified_at: datetime = field(default_factory=datetime.now)
    
    @property
    def is_valid(self) -> bool:
        """Check if DOI is valid and not retracted."""
        return self.status == DOIStatus.VALID and not self.retracted
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "doi": self.doi,
            "status": self.status.value,
            "is_valid": self.is_valid,
            "title": self.title,
            "authors": self.authors,
            "publication_date": self.publication_date.isoformat() if self.publication_date else None,
            "journal": self.journal,
            "abstract": self.abstract,
            "retracted": self.retracted,
            "retraction_date": self.retraction_date.isoformat() if self.retraction_date else None,
            "retraction_reason": self.retraction_reason,
            "publisher_reliability": self.publisher_reliability,
            "verified_at": self.verified_at.isoformat(),
        }


@dataclass
class SourceReliabilityScore:
    """Computed reliability score for an external source."""
    
    overall: float  # 0.0-1.0 final score
    
    # Component scores
    category_score: float  # Base score from category
    liveness_score: float  # 1.0 if live, 0.0 if dead
    content_match_score: float  # Semantic similarity
    freshness_score: float  # Based on source age
    registry_score: float  # Bonus if in trusted registry
    
    # Penalties
    staleness_penalty: float = 0.0
    redirect_penalty: float = 0.0
    
    # Metadata
    computed_at: datetime = field(default_factory=datetime.now)
    
    @property
    def meets_l4_threshold(self) -> bool:
        """Check if score meets L4 elevation threshold."""
        return self.overall >= ExternalSourceConstants.MIN_VERIFIED_SOURCE_RELIABILITY
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "overall": self.overall,
            "meets_l4_threshold": self.meets_l4_threshold,
            "components": {
                "category_score": self.category_score,
                "liveness_score": self.liveness_score,
                "content_match_score": self.content_match_score,
                "freshness_score": self.freshness_score,
                "registry_score": self.registry_score,
            },
            "penalties": {
                "staleness_penalty": self.staleness_penalty,
                "redirect_penalty": self.redirect_penalty,
            },
            "computed_at": self.computed_at.isoformat(),
        }


@dataclass
class ExternalSourceVerification:
    """Complete verification record for an external source."""
    
    id: UUID
    belief_id: UUID
    
    # Source identifiers
    url: str | None = None
    doi: str | None = None
    isbn: str | None = None
    citation: str | None = None  # Human-readable citation
    
    # Verification results
    status: SourceVerificationStatus = SourceVerificationStatus.PENDING
    liveness: LivenessCheckResult | None = None
    content_match: ContentMatchResult | None = None
    doi_verification: DOIVerificationResult | None = None
    reliability: SourceReliabilityScore | None = None
    
    # Source classification
    category: SourceCategory = SourceCategory.UNKNOWN
    
    # Content snapshot
    content_hash: str | None = None  # SHA-256 of fetched content
    archived_at: datetime | None = None
    archive_url: str | None = None  # Archive.org or similar
    
    # Timing
    created_at: datetime = field(default_factory=datetime.now)
    verified_at: datetime | None = None
    expires_at: datetime | None = None
    
    # Metadata
    verified_by: str | None = None  # DID of verifier (or 'system')
    
    @property
    def is_verified(self) -> bool:
        """Check if source has been successfully verified."""
        return self.status == SourceVerificationStatus.VERIFIED
    
    @property
    def source_identifier(self) -> str:
        """Get primary source identifier."""
        if self.doi:
            return f"doi:{self.doi}"
        if self.url:
            return self.url
        if self.isbn:
            return f"isbn:{self.isbn}"
        return self.citation or "unknown"
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "id": str(self.id),
            "belief_id": str(self.belief_id),
            "source_identifier": self.source_identifier,
            "url": self.url,
            "doi": self.doi,
            "isbn": self.isbn,
            "citation": self.citation,
            "status": self.status.value,
            "is_verified": self.is_verified,
            "liveness": self.liveness.to_dict() if self.liveness else None,
            "content_match": self.content_match.to_dict() if self.content_match else None,
            "doi_verification": self.doi_verification.to_dict() if self.doi_verification else None,
            "reliability": self.reliability.to_dict() if self.reliability else None,
            "category": self.category.value,
            "content_hash": self.content_hash,
            "archived_at": self.archived_at.isoformat() if self.archived_at else None,
            "archive_url": self.archive_url,
            "created_at": self.created_at.isoformat(),
            "verified_at": self.verified_at.isoformat() if self.verified_at else None,
            "expires_at": self.expires_at.isoformat() if self.expires_at else None,
            "verified_by": self.verified_by,
        }


# =============================================================================
# L4 ELEVATION REQUIREMENTS
# =============================================================================

@dataclass 
class L4SourceRequirements:
    """Requirements check result for L4 elevation external sources."""
    
    belief_id: UUID
    
    # Requirement status
    has_external_sources: bool = False
    has_verified_sources: bool = False
    meets_reliability_threshold: bool = False
    meets_content_match_threshold: bool = False
    all_requirements_met: bool = False
    
    # Details
    total_sources: int = 0
    verified_sources: int = 0
    failed_sources: int = 0
    
    # Best source
    best_source_id: UUID | None = None
    best_reliability_score: float = 0.0
    best_content_match_score: float = 0.0
    
    # Issues
    issues: list[str] = field(default_factory=list)
    
    # Timing
    checked_at: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "belief_id": str(self.belief_id),
            "has_external_sources": self.has_external_sources,
            "has_verified_sources": self.has_verified_sources,
            "meets_reliability_threshold": self.meets_reliability_threshold,
            "meets_content_match_threshold": self.meets_content_match_threshold,
            "all_requirements_met": self.all_requirements_met,
            "total_sources": self.total_sources,
            "verified_sources": self.verified_sources,
            "failed_sources": self.failed_sources,
            "best_source_id": str(self.best_source_id) if self.best_source_id else None,
            "best_reliability_score": self.best_reliability_score,
            "best_content_match_score": self.best_content_match_score,
            "issues": self.issues,
            "checked_at": self.checked_at.isoformat(),
        }


# =============================================================================
# VERIFICATION SERVICE
# =============================================================================

class ExternalSourceVerificationService:
    """Service for verifying external sources for L4 elevation.
    
    This service handles:
    1. Source liveness checks (URL/DOI resolution)
    2. Content matching (semantic similarity)
    3. Reliability scoring
    4. L4 requirement verification
    
    In production, this would use:
    - HTTP client for liveness checks
    - Embedding model for semantic similarity
    - DOI resolver API
    - Database for persistence
    """
    
    def __init__(self, registry: TrustedSourceRegistry | None = None):
        self.registry = registry or get_registry()
        
        # In-memory storage for testing
        self._verifications: dict[UUID, ExternalSourceVerification] = {}
        self._verifications_by_belief: dict[UUID, list[UUID]] = {}
        
        # Liveness cache
        self._liveness_cache: dict[str, LivenessCheckResult] = {}
    
    def create_verification(
        self,
        belief_id: UUID,
        url: str | None = None,
        doi: str | None = None,
        isbn: str | None = None,
        citation: str | None = None,
    ) -> ExternalSourceVerification:
        """Create a new external source verification record."""
        if not any([url, doi, isbn]):
            raise ValueError("At least one of url, doi, or isbn is required")
        
        # Check blocklist
        if url and self.registry.is_blocklisted(url):
            verification = ExternalSourceVerification(
                id=uuid4(),
                belief_id=belief_id,
                url=url,
                doi=doi,
                isbn=isbn,
                citation=citation,
                status=SourceVerificationStatus.BLOCKED,
                category=SourceCategory.UNKNOWN,
            )
        else:
            # Classify source
            category = self.registry.classify_source(url=url, doi=doi)
            
            verification = ExternalSourceVerification(
                id=uuid4(),
                belief_id=belief_id,
                url=url,
                doi=doi,
                isbn=isbn,
                citation=citation,
                status=SourceVerificationStatus.PENDING,
                category=category,
            )
        
        # Store
        self._verifications[verification.id] = verification
        if belief_id not in self._verifications_by_belief:
            self._verifications_by_belief[belief_id] = []
        self._verifications_by_belief[belief_id].append(verification.id)
        
        logger.info(f"Created source verification {verification.id} for belief {belief_id}")
        return verification
    
    def check_liveness(
        self,
        verification_id: UUID,
        use_cache: bool = True,
    ) -> LivenessCheckResult:
        """Perform liveness check for a source.
        
        In production, this would:
        1. Make HTTP HEAD/GET request to URL
        2. Resolve DOI via doi.org API
        3. Check ISBN via library APIs
        
        For now, returns mock results.
        """
        verification = self._verifications.get(verification_id)
        if not verification:
            raise ValueError(f"Verification {verification_id} not found")
        
        source_key = verification.source_identifier
        
        # Check cache
        if use_cache and source_key in self._liveness_cache:
            cached = self._liveness_cache[source_key]
            cache_age = datetime.now() - cached.checked_at
            if cache_age < timedelta(hours=ExternalSourceConstants.LIVENESS_CACHE_TTL_HOURS):
                verification.liveness = cached
                return cached
        
        # Simulate liveness check
        # In production: actual HTTP request / API call
        result = self._simulate_liveness_check(verification)
        
        # Cache result
        self._liveness_cache[source_key] = result
        verification.liveness = result
        
        # Update status if failed
        if not result.is_live:
            verification.status = SourceVerificationStatus.FAILED_LIVENESS
        
        return result
    
    def _simulate_liveness_check(
        self, 
        verification: ExternalSourceVerification
    ) -> LivenessCheckResult:
        """Simulate a liveness check (for testing without network)."""
        # Default to live for testing
        # In production: actual HTTP/API calls
        return LivenessCheckResult(
            status=SourceLivenessStatus.LIVE,
            http_status=200,
            final_url=verification.url,
            content_type="text/html",
            content_length=10000,
            response_time_ms=150,
        )
    
    def verify_doi(
        self,
        verification_id: UUID,
    ) -> DOIVerificationResult | None:
        """Verify a DOI reference.
        
        In production, this would:
        1. Query doi.org/CrossRef API for metadata
        2. Check Retraction Watch database
        3. Verify publisher authenticity
        """
        verification = self._verifications.get(verification_id)
        if not verification or not verification.doi:
            return None
        
        # Simulate DOI verification
        result = self._simulate_doi_verification(verification.doi)
        verification.doi_verification = result
        
        if not result.is_valid:
            verification.status = SourceVerificationStatus.FAILED_LIVENESS
        
        return result
    
    def _simulate_doi_verification(self, doi: str) -> DOIVerificationResult:
        """Simulate DOI verification (for testing without network)."""
        # Get publisher info from registry
        prefix_info = self.registry.get_doi_prefix_info(doi)
        publisher_reliability = prefix_info.reliability if prefix_info else 0.7
        
        return DOIVerificationResult(
            doi=doi,
            status=DOIStatus.VALID,
            title="Simulated Paper Title",
            authors=["Author A", "Author B"],
            publication_date=datetime.now() - timedelta(days=180),
            journal="Simulated Journal",
            abstract="This is a simulated abstract for testing.",
            retracted=False,
            publisher_reliability=publisher_reliability,
        )
    
    def check_content_match(
        self,
        verification_id: UUID,
        belief_content: str,
        fetched_content: str | None = None,
    ) -> ContentMatchResult:
        """Check if external source content matches the belief claim.
        
        In production, this would:
        1. Fetch content from source
        2. Generate embeddings for belief and content
        3. Compute semantic similarity
        4. Extract matching passages
        """
        verification = self._verifications.get(verification_id)
        if not verification:
            raise ValueError(f"Verification {verification_id} not found")
        
        # Simulate content matching
        result = self._simulate_content_match(belief_content, fetched_content)
        verification.content_match = result
        
        if not result.meets_threshold:
            verification.status = SourceVerificationStatus.FAILED_CONTENT
        
        return result
    
    def _simulate_content_match(
        self, 
        belief_content: str,
        fetched_content: str | None = None,
    ) -> ContentMatchResult:
        """Simulate content matching (for testing without embedding model)."""
        # Simple keyword overlap for simulation
        # In production: embedding-based semantic similarity
        belief_words = set(belief_content.lower().split())
        content_words = set((fetched_content or "simulated content relevant to belief scientific research findings").lower().split())
        
        if not belief_words:
            similarity = 0.0
        else:
            overlap = len(belief_words & content_words)
            similarity = overlap / len(belief_words)
            # Boost for simulation - ensure we generally pass the threshold
            # This simulates "good enough" content matching in test mode
            similarity = min(1.0, max(0.7, similarity + 0.6))
        
        return ContentMatchResult(
            similarity_score=similarity,
            matched_passages=["Relevant passage from source"],
            method="keyword_simulation",
            content_length_chars=len(fetched_content or ""),
        )
    
    def compute_reliability(
        self,
        verification_id: UUID,
        source_date: datetime | None = None,
    ) -> SourceReliabilityScore:
        """Compute overall reliability score for a verified source."""
        verification = self._verifications.get(verification_id)
        if not verification:
            raise ValueError(f"Verification {verification_id} not found")
        
        # Category score
        category_score = verification.category.base_reliability
        
        # Check for registry bonus
        registry_bonus = 0.0
        if verification.url:
            domain_info = self.registry.get_domain_info(verification.url)
            if domain_info:
                registry_bonus = 0.1
                category_score = domain_info.reliability
        
        if verification.doi:
            prefix_info = self.registry.get_doi_prefix_info(verification.doi)
            if prefix_info:
                registry_bonus = 0.1
                category_score = prefix_info.reliability
        
        # Liveness score
        liveness_score = 1.0 if verification.liveness and verification.liveness.is_live else 0.0
        
        # Content match score
        content_match_score = 0.0
        if verification.content_match:
            content_match_score = verification.content_match.similarity_score
        
        # Freshness score
        freshness_score = 1.0
        staleness_penalty = 0.0
        if source_date:
            days_old = (datetime.now() - source_date).days
            if days_old > ExternalSourceConstants.STALE_SOURCE_THRESHOLD_DAYS:
                staleness_penalty = 0.2
                freshness_score = 0.6
            elif days_old < 30:
                freshness_score = 1.0 + ExternalSourceConstants.RECENT_SOURCE_BONUS
        
        # Redirect penalty
        redirect_penalty = 0.0
        if verification.liveness and verification.liveness.status == SourceLivenessStatus.REDIRECT:
            redirect_penalty = 0.1
        
        # Compute overall (weighted combination)
        overall = (
            0.25 * category_score +
            0.20 * liveness_score +
            0.35 * content_match_score +
            0.10 * freshness_score +
            0.10 * (1.0 + registry_bonus)
        ) - staleness_penalty - redirect_penalty
        
        overall = max(0.0, min(1.0, overall))
        
        result = SourceReliabilityScore(
            overall=overall,
            category_score=category_score,
            liveness_score=liveness_score,
            content_match_score=content_match_score,
            freshness_score=freshness_score,
            registry_score=1.0 + registry_bonus,
            staleness_penalty=staleness_penalty,
            redirect_penalty=redirect_penalty,
        )
        
        verification.reliability = result
        return result
    
    def verify_source(
        self,
        verification_id: UUID,
        belief_content: str,
        source_date: datetime | None = None,
    ) -> ExternalSourceVerification:
        """Run full verification workflow for a source.
        
        Steps:
        1. Check liveness (URL/DOI resolves)
        2. Verify DOI if present
        3. Check content match
        4. Compute reliability score
        5. Update status
        """
        verification = self._verifications.get(verification_id)
        if not verification:
            raise ValueError(f"Verification {verification_id} not found")
        
        if verification.status == SourceVerificationStatus.BLOCKED:
            return verification
        
        # Step 1: Liveness check
        liveness = self.check_liveness(verification_id)
        if not liveness.is_live:
            return verification
        
        # Step 2: DOI verification (if applicable)
        if verification.doi:
            doi_result = self.verify_doi(verification_id)
            if doi_result and not doi_result.is_valid:
                return verification
        
        # Step 3: Content match
        content_match = self.check_content_match(
            verification_id, 
            belief_content,
        )
        if not content_match.meets_threshold:
            return verification
        
        # Step 4: Compute reliability
        reliability = self.compute_reliability(verification_id, source_date)
        if not reliability.meets_l4_threshold:
            verification.status = SourceVerificationStatus.FAILED_RELIABILITY
            return verification
        
        # All checks passed
        verification.status = SourceVerificationStatus.VERIFIED
        verification.verified_at = datetime.now()
        verification.expires_at = datetime.now() + timedelta(
            hours=ExternalSourceConstants.LIVENESS_CACHE_TTL_HOURS * 7
        )
        verification.content_hash = hashlib.sha256(
            belief_content.encode()
        ).hexdigest()
        
        logger.info(
            f"Source {verification.source_identifier} verified for belief {verification.belief_id} "
            f"(reliability: {reliability.overall:.2f})"
        )
        
        return verification
    
    def check_l4_requirements(
        self,
        belief_id: UUID,
        belief_content: str,
    ) -> L4SourceRequirements:
        """Check if a belief meets L4 external source requirements.
        
        Requirements for L4 elevation:
        1. At least MIN_EXTERNAL_SOURCES_FOR_L4 external sources
        2. At least one source must be verified
        3. Best source reliability >= MIN_VERIFIED_SOURCE_RELIABILITY
        4. Best content match >= MIN_CONTENT_MATCH_SCORE
        """
        result = L4SourceRequirements(belief_id=belief_id)
        
        # Get all verifications for this belief
        verification_ids = self._verifications_by_belief.get(belief_id, [])
        verifications = [self._verifications[vid] for vid in verification_ids]
        
        result.total_sources = len(verifications)
        result.has_external_sources = result.total_sources >= ExternalSourceConstants.MIN_EXTERNAL_SOURCES_FOR_L4
        
        if not result.has_external_sources:
            result.issues.append(
                f"Insufficient external sources: {result.total_sources} < "
                f"{ExternalSourceConstants.MIN_EXTERNAL_SOURCES_FOR_L4}"
            )
            return result
        
        # Count verified vs failed
        verified = [v for v in verifications if v.status == SourceVerificationStatus.VERIFIED]
        failed = [v for v in verifications if v.status.value.startswith("failed")]
        
        result.verified_sources = len(verified)
        result.failed_sources = len(failed)
        result.has_verified_sources = result.verified_sources > 0
        
        if not result.has_verified_sources:
            result.issues.append("No verified external sources")
            return result
        
        # Find best source
        best_reliability = 0.0
        best_content_match = 0.0
        best_source: ExternalSourceVerification | None = None
        
        for v in verified:
            if v.reliability and v.reliability.overall > best_reliability:
                best_reliability = v.reliability.overall
                best_source = v
            if v.content_match and v.content_match.similarity_score > best_content_match:
                best_content_match = v.content_match.similarity_score
        
        result.best_reliability_score = best_reliability
        result.best_content_match_score = best_content_match
        if best_source:
            result.best_source_id = best_source.id
        
        # Check thresholds
        result.meets_reliability_threshold = (
            best_reliability >= ExternalSourceConstants.MIN_VERIFIED_SOURCE_RELIABILITY
        )
        result.meets_content_match_threshold = (
            best_content_match >= ExternalSourceConstants.MIN_CONTENT_MATCH_SCORE
        )
        
        if not result.meets_reliability_threshold:
            result.issues.append(
                f"Best source reliability {best_reliability:.2f} < "
                f"{ExternalSourceConstants.MIN_VERIFIED_SOURCE_RELIABILITY}"
            )
        
        if not result.meets_content_match_threshold:
            result.issues.append(
                f"Best content match {best_content_match:.2f} < "
                f"{ExternalSourceConstants.MIN_CONTENT_MATCH_SCORE}"
            )
        
        # All requirements met?
        result.all_requirements_met = (
            result.has_external_sources and
            result.has_verified_sources and
            result.meets_reliability_threshold and
            result.meets_content_match_threshold
        )
        
        return result
    
    def get_verification(self, verification_id: UUID) -> ExternalSourceVerification | None:
        """Get a verification by ID."""
        return self._verifications.get(verification_id)
    
    def get_verifications_for_belief(self, belief_id: UUID) -> list[ExternalSourceVerification]:
        """Get all verifications for a belief."""
        ids = self._verifications_by_belief.get(belief_id, [])
        return [self._verifications[vid] for vid in ids if vid in self._verifications]
    
    def get_verified_sources_for_belief(self, belief_id: UUID) -> list[ExternalSourceVerification]:
        """Get only verified sources for a belief."""
        return [
            v for v in self.get_verifications_for_belief(belief_id)
            if v.status == SourceVerificationStatus.VERIFIED
        ]


# =============================================================================
# MODULE-LEVEL CONVENIENCE FUNCTIONS
# =============================================================================

def verify_external_source(
    belief_id: UUID,
    belief_content: str,
    url: str | None = None,
    doi: str | None = None,
    isbn: str | None = None,
    citation: str | None = None,
    service: ExternalSourceVerificationService | None = None,
) -> ExternalSourceVerification:
    """Convenience function to verify a single external source.
    
    Args:
        belief_id: UUID of the belief being supported
        belief_content: Text content of the belief
        url: URL of the external source
        doi: DOI identifier
        isbn: ISBN for books
        citation: Human-readable citation
        service: Optional service instance (creates new if None)
    
    Returns:
        ExternalSourceVerification with verification results
    """
    svc = service or ExternalSourceVerificationService()
    verification = svc.create_verification(
        belief_id=belief_id,
        url=url,
        doi=doi,
        isbn=isbn,
        citation=citation,
    )
    return svc.verify_source(verification.id, belief_content)


def check_belief_l4_readiness(
    belief_id: UUID,
    belief_content: str,
    sources: list[dict[str, str]],
    service: ExternalSourceVerificationService | None = None,
) -> L4SourceRequirements:
    """Check if a belief has sufficient external sources for L4 elevation.
    
    Args:
        belief_id: UUID of the belief
        belief_content: Text content of the belief
        sources: List of source dicts with 'url', 'doi', 'isbn', 'citation' keys
        service: Optional service instance
    
    Returns:
        L4SourceRequirements with detailed check results
    """
    svc = service or ExternalSourceVerificationService()
    
    # Create and verify all sources
    for source in sources:
        verification = svc.create_verification(
            belief_id=belief_id,
            url=source.get("url"),
            doi=source.get("doi"),
            isbn=source.get("isbn"),
            citation=source.get("citation"),
        )
        svc.verify_source(verification.id, belief_content)
    
    return svc.check_l4_requirements(belief_id, belief_content)
